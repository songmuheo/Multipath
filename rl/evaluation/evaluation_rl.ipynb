{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward 수렴 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = '2024_11_28_13_21' \n",
    "\n",
    "# Example usage\n",
    "log_dir_episode = f'/home/songmu/multipath/rl/results/{folder}/logs/episode'\n",
    "log_dir_step = f'/home/songmu/multipath/rl/results/{folder}/logs/step'\n",
    "output_dir = f'output/{folder}'\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Learning Rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/multipath/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.conda/envs/multipath/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/multipath/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Learning Rate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m\n\u001b[1;32m     90\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphs saved in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m \u001b[43manalyze_combined_episode_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir_episode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 83\u001b[0m, in \u001b[0;36manalyze_combined_episode_logs\u001b[0;34m(log_dir, output_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Plot Learning rate\u001b[39;00m\n\u001b[1;32m     82\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 83\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(combined_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLearning Rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, markersize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/multipath/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.conda/envs/multipath/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Learning Rate'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_combined_episode_logs(log_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Analyze combined episode logs and generate graphs for each metric.\n",
    "\n",
    "    Parameters:\n",
    "        log_dir (str): Path to the directory containing episode logs.\n",
    "        output_dir (str): Path to save the output graphs.\n",
    "    \"\"\"\n",
    "    # List all log files in the directory\n",
    "    log_files = [f for f in os.listdir(log_dir) if f.endswith('.csv')]\n",
    "    if not log_files:\n",
    "        print(\"No log files found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    # Combine all logs into a single DataFrame\n",
    "    combined_data = pd.DataFrame()\n",
    "    for log_file in log_files:\n",
    "        log_path = os.path.join(log_dir, log_file)\n",
    "        try:\n",
    "            # Read the log file and append to combined DataFrame\n",
    "            log_data = pd.read_csv(log_path)\n",
    "            combined_data = pd.concat([combined_data, log_data], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {log_file}: {e}\")\n",
    "\n",
    "    if combined_data.empty:\n",
    "        print(\"No data found in the logs.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the data is sorted by episode\n",
    "    combined_data.sort_values(by='Episode', inplace=True)\n",
    "\n",
    "    # Plot Total Reward per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Return'], marker='o', markersize = 2, label='Return')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'total_reward_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Episode Length per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Episode Length'], marker='o', markersize = 2, label='Episode Length')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Episode Length')\n",
    "    plt.title('Episode Length per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'episode_length_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Average Reward per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Average Reward (100 eps)'], marker='o', markersize = 2, label='Average Reward')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.title('Average Reward per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'average_reward_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Average Loss per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Average Loss'], marker='o', markersize = 2, label='Average Loss')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Average Loss per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'average_loss_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Learning rate\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Learning Rate'], marker='o', markersize = 2, label='Learning Rate')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'learning_rate.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Graphs saved in {output_dir}\")\n",
    "\n",
    "analyze_combined_episode_logs(log_dir_episode, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action distribution plot saved to: output/2024_11_28_13_21/action_distribution.png\n",
      "SSIM over Steps plot saved to: output/2024_11_28_13_21/ssim_over_steps.png\n",
      "Data Size over Steps plot saved to: output/2024_11_28_13_21/data size_over_steps.png\n",
      "Reward over Steps plot saved to: output/2024_11_28_13_21/reward_over_steps.png\n",
      "Action over Steps plot saved to: output/2024_11_28_13_21/action_over_steps.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_filtered_logs(log_dir_step, episode_range=None):\n",
    "    \"\"\"\n",
    "    지정된 범위의 에피소드 데이터만 로드하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        log_dir_step (str): Step 로그 파일들이 있는 디렉토리 경로.\n",
    "        episode_range (list or range): 로드할 에피소드 번호 리스트 또는 범위.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: 필터링된 데이터프레임.\n",
    "    \"\"\"\n",
    "    log_files = sorted([os.path.join(log_dir_step, f) for f in os.listdir(log_dir_step) if f.endswith('.csv')])\n",
    "\n",
    "    if not log_files:\n",
    "        print(\"No log files found in the directory!\")\n",
    "        return None\n",
    "\n",
    "    filtered_logs = []\n",
    "    for file in log_files:\n",
    "        # 데이터 로드\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # 지정된 에피소드 범위만 필터링\n",
    "        if episode_range:\n",
    "            df = df[df['Episode'].isin(episode_range)]\n",
    "\n",
    "        if not df.empty:\n",
    "            filtered_logs.append(df)\n",
    "\n",
    "    if not filtered_logs:\n",
    "        print(\"No logs matched the specified episode range.\")\n",
    "        return None\n",
    "\n",
    "    # 필터링된 데이터를 병합\n",
    "    return pd.concat(filtered_logs, ignore_index=True)\n",
    "\n",
    "def plot_action_over_steps(filtered_logs, output_dir):\n",
    "    \"\"\"\n",
    "    Step별 Action 선택을 시각화하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        filtered_logs (pd.DataFrame): 필터링된 로그 데이터.\n",
    "        output_dir (str): 그래프 저장 디렉토리.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for episode in filtered_logs['Episode'].unique():\n",
    "        episode_data = filtered_logs[filtered_logs['Episode'] == episode]\n",
    "        plt.plot(episode_data['Step'], episode_data['Action'], label=f\"Episode {episode}\", alpha=0.7, linestyle='none', marker='o', markersize=0.7)\n",
    "    \n",
    "    plt.title(\"Action Selection over Steps\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Action\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.7)\n",
    "    \n",
    "    # 그래프 저장\n",
    "    output_path = os.path.join(output_dir, 'action_over_steps.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Action over Steps plot saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def plot_action_distribution(filtered_logs, output_dir):\n",
    "    \"\"\"\n",
    "    Action 분포를 시각화하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        filtered_logs (pd.DataFrame): 필터링된 로그 데이터.\n",
    "        output_dir (str): 그래프 저장 디렉토리.\n",
    "    \"\"\"\n",
    "    # Action 분포 시각화\n",
    "    action_counts = filtered_logs['Action'].value_counts().sort_index()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    action_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "    plt.title('Action Distribution')\n",
    "    plt.xlabel('Action')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 그래프 저장\n",
    "    output_path = os.path.join(output_dir, 'action_distribution.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Action distribution plot saved to: {output_path}\")\n",
    "\n",
    "def plot_metrics_over_steps(filtered_logs, output_dir):\n",
    "    \"\"\"\n",
    "    Step별 주요 메트릭 시각화 (SSIM, Data Size, Reward).\n",
    "    \n",
    "    Args:\n",
    "        filtered_logs (pd.DataFrame): 필터링된 로그 데이터.\n",
    "        output_dir (str): 그래프 저장 디렉토리.\n",
    "    \"\"\"\n",
    "    metrics = ['SSIM', 'Data Size', 'Reward']\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for episode in filtered_logs['Episode'].unique():\n",
    "            episode_data = filtered_logs[filtered_logs['Episode'] == episode]\n",
    "            plt.plot(episode_data['Step'], episode_data[metric], label=f\"Episode {episode}\", linestyle='none', marker='o', markersize=0.7)\n",
    "        \n",
    "        plt.title(f'{metric} over Steps')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.7)\n",
    "\n",
    "        # 그래프 저장\n",
    "        output_path = os.path.join(output_dir, f'{metric.lower()}_over_steps.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        print(f\"{metric} over Steps plot saved to: {output_path}\")\n",
    "\n",
    "# Example usage \n",
    "# log_dir_step = '/path/to/logs/step'\n",
    "# output_dir = '/path/to/output'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 원하는 에피소드 범위 설정\n",
    "episode_range = range(450, 451)\n",
    "\n",
    "# 로그 데이터 로드\n",
    "filtered_logs = load_filtered_logs(log_dir_step, episode_range)\n",
    "\n",
    "if filtered_logs is not None:\n",
    "    # Action 분포 시각화\n",
    "    plot_action_distribution(filtered_logs, output_dir)\n",
    "    # Step별 메트릭 시각화\n",
    "    plot_metrics_over_steps(filtered_logs, output_dir)\n",
    "    # Step 별 Action\n",
    "    plot_action_over_steps(filtered_logs, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
